/**
 * å¤§è¯­è¨€æ¨¡å‹æ’è¡Œæ¦œé…ç½®æ–‡ä»¶
 * æ•°æ®æ¥æºï¼šChatbot Arena, HumanEval, MMLU ç­‰åŸºå‡†æµ‹è¯•
 * æ›´æ–°æ—¥æœŸï¼š2024å¹´10æœˆ
 */

export interface LLMRanking {
  id: string
  modelName: string
  provider: string
  scores: {
    overall: number      // ç»¼åˆè¯„åˆ† (Elo rating 1000-1400)
    coding: number       // ç¼–ç¨‹èƒ½åŠ› (0-100)
    math: number         // æ•°å­¦æ¨ç† (0-100)
    reasoning: number    // æ¨ç†èƒ½åŠ› (0-100)
    mmlu: number        // å¤šä»»åŠ¡ç†è§£ (0-100)
  }
  contextLength: number  // ä¸Šä¸‹æ–‡é•¿åº¦ (K tokens)
  pricing: {
    input: number       // è¾“å…¥ä»·æ ¼ ($/1M tokens)
    output: number      // è¾“å‡ºä»·æ ¼ ($/1M tokens)
  }
  isOpenSource: boolean
  releaseDate: string
  highlights: HighlightBadge[]
}

export type HighlightBadge = 
  | 'best-overall'      // ğŸ† ç»¼åˆæ¦œé¦–
  | 'best-coding'       // ğŸ’» ç¼–ç¨‹ä¹‹ç‹
  | 'best-math'         // ğŸ§® æ•°å­¦å† å†›
  | 'best-reasoning'    // ğŸ§  æ¨ç†å¤§å¸ˆ
  | 'best-value'        // ğŸ’° æ€§ä»·æ¯”ä¹‹ç‹
  | 'open-source'       // ğŸ”“ å¼€æº
  | 'long-context'      // ğŸ“š è¶…é•¿ä¸Šä¸‹æ–‡
  | 'multilingual'      // ğŸŒ å¤šè¯­è¨€

export type SortBy = 'overall' | 'coding' | 'math' | 'reasoning' | 'value'

/**
 * LLM æ’è¡Œæ¦œæ•°æ®
 * æ•°æ®åŸºäºæœ€æ–°çš„å…¬å¼€åŸºå‡†æµ‹è¯•ç»“æœ
 */
export const llmRankings: LLMRanking[] = [
  {
    id: 'claude-35-sonnet',
    modelName: 'Claude 3.5 Sonnet',
    provider: 'Anthropic',
    scores: {
      overall: 1324,  // Chatbot Arena Elo
      coding: 96,     // ç¼–ç¨‹èƒ½åŠ›æå¼º
      math: 90,
      reasoning: 94,
      mmlu: 88.7
    },
    contextLength: 200,
    pricing: {
      input: 3.0,
      output: 15.0
    },
    isOpenSource: false,
    releaseDate: '2024-06-20',
    highlights: ['best-overall', 'best-coding']
  },
  {
    id: 'gpt-4-turbo',
    modelName: 'GPT-4 Turbo',
    provider: 'OpenAI',
    scores: {
      overall: 1287,
      coding: 92,
      math: 88,
      reasoning: 91,
      mmlu: 86.4
    },
    contextLength: 128,
    pricing: {
      input: 10.0,
      output: 30.0
    },
    isOpenSource: false,
    releaseDate: '2024-04-09',
    highlights: ['best-coding']
  },
  {
    id: 'gemini-15-pro',
    modelName: 'Gemini 1.5 Pro',
    provider: 'Google',
    scores: {
      overall: 1268,
      coding: 88,
      math: 86,
      reasoning: 89,
      mmlu: 85.9
    },
    contextLength: 1000,  // 1M tokens
    pricing: {
      input: 3.5,
      output: 10.5
    },
    isOpenSource: false,
    releaseDate: '2024-02-15',
    highlights: ['long-context']
  },
  {
    id: 'claude-3-opus',
    modelName: 'Claude 3 Opus',
    provider: 'Anthropic',
    scores: {
      overall: 1253,
      coding: 90,
      math: 89,
      reasoning: 93,
      mmlu: 86.8
    },
    contextLength: 200,
    pricing: {
      input: 15.0,
      output: 75.0
    },
    isOpenSource: false,
    releaseDate: '2024-03-04',
    highlights: ['best-reasoning']
  },
  {
    id: 'gpt-4o',
    modelName: 'GPT-4o',
    provider: 'OpenAI',
    scores: {
      overall: 1246,
      coding: 90,
      math: 87,
      reasoning: 88,
      mmlu: 87.2
    },
    contextLength: 128,
    pricing: {
      input: 5.0,
      output: 15.0
    },
    isOpenSource: false,
    releaseDate: '2024-05-13',
    highlights: ['multilingual']
  },
  {
    id: 'llama-31-405b',
    modelName: 'Llama 3.1 405B',
    provider: 'Meta',
    scores: {
      overall: 1224,
      coding: 87,
      math: 85,
      reasoning: 86,
      mmlu: 85.2
    },
    contextLength: 128,
    pricing: {
      input: 0.0,  // å¼€æºï¼Œå¯è‡ªéƒ¨ç½²
      output: 0.0
    },
    isOpenSource: true,
    releaseDate: '2024-07-23',
    highlights: ['open-source']
  },
  {
    id: 'deepseek-v25',
    modelName: 'DeepSeek V2.5',
    provider: 'DeepSeek',
    scores: {
      overall: 1195,
      coding: 89,  // ç¼–ç¨‹èƒ½åŠ›å‡ºè‰²
      math: 84,
      reasoning: 83,
      mmlu: 81.7
    },
    contextLength: 128,
    pricing: {
      input: 0.14,   // æä½ä»·æ ¼
      output: 0.28
    },
    isOpenSource: false,
    releaseDate: '2024-09-05',
    highlights: ['best-value', 'best-coding']
  },
  {
    id: 'qwen-25-72b',
    modelName: 'Qwen 2.5 72B',
    provider: 'Alibaba Cloud',
    scores: {
      overall: 1188,
      coding: 86,
      math: 83,
      reasoning: 82,
      mmlu: 84.2
    },
    contextLength: 128,
    pricing: {
      input: 0.35,
      output: 1.15
    },
    isOpenSource: true,
    releaseDate: '2024-09-19',
    highlights: ['open-source', 'multilingual', 'best-value']
  },
  {
    id: 'mistral-large-2',
    modelName: 'Mistral Large 2',
    provider: 'Mistral AI',
    scores: {
      overall: 1176,
      coding: 85,
      math: 82,
      reasoning: 84,
      mmlu: 84.0
    },
    contextLength: 128,
    pricing: {
      input: 3.0,
      output: 9.0
    },
    isOpenSource: false,
    releaseDate: '2024-07-24',
    highlights: ['multilingual']
  },
  {
    id: 'command-r-plus',
    modelName: 'Command R+',
    provider: 'Cohere',
    scores: {
      overall: 1158,
      coding: 81,
      math: 79,
      reasoning: 80,
      mmlu: 81.5
    },
    contextLength: 128,
    pricing: {
      input: 3.0,
      output: 15.0
    },
    isOpenSource: false,
    releaseDate: '2024-04-04',
    highlights: ['multilingual']
  },
  {
    id: 'llama-31-70b',
    modelName: 'Llama 3.1 70B',
    provider: 'Meta',
    scores: {
      overall: 1145,
      coding: 80,
      math: 78,
      reasoning: 79,
      mmlu: 79.3
    },
    contextLength: 128,
    pricing: {
      input: 0.0,
      output: 0.0
    },
    isOpenSource: true,
    releaseDate: '2024-07-23',
    highlights: ['open-source', 'best-value']
  },
  {
    id: 'gemini-15-flash',
    modelName: 'Gemini 1.5 Flash',
    provider: 'Google',
    scores: {
      overall: 1131,
      coding: 78,
      math: 76,
      reasoning: 77,
      mmlu: 78.9
    },
    contextLength: 1000,
    pricing: {
      input: 0.075,
      output: 0.30
    },
    isOpenSource: false,
    releaseDate: '2024-05-14',
    highlights: ['best-value', 'long-context']
  }
]

/**
 * æ ¹æ®ä¸åŒç»´åº¦æ’åº
 */
export function sortRankings(rankings: LLMRanking[], sortBy: SortBy): LLMRanking[] {
  const sorted = [...rankings]
  
  switch (sortBy) {
    case 'overall':
      return sorted.sort((a, b) => b.scores.overall - a.scores.overall)
    case 'coding':
      return sorted.sort((a, b) => b.scores.coding - a.scores.coding)
    case 'math':
      return sorted.sort((a, b) => b.scores.math - a.scores.math)
    case 'reasoning':
      return sorted.sort((a, b) => b.scores.reasoning - a.scores.reasoning)
    case 'value':
      // æ€§ä»·æ¯” = æ€§èƒ½ / ä»·æ ¼ (è€ƒè™‘å¼€æºæ¨¡å‹ä¸ºæœ€é«˜æ€§ä»·æ¯”)
      return sorted.sort((a, b) => {
        const aValue = a.isOpenSource ? 9999 : a.scores.overall / ((a.pricing.input + a.pricing.output) / 2)
        const bValue = b.isOpenSource ? 9999 : b.scores.overall / ((b.pricing.input + b.pricing.output) / 2)
        return bValue - aValue
      })
    default:
      return sorted
  }
}

/**
 * è·å–å¾½ç« çš„æ˜¾ç¤ºä¿¡æ¯
 */
export function getBadgeInfo(badge: HighlightBadge): { label: { en: string; zh: string }; variant: string } {
  const badgeMap: Record<HighlightBadge, { label: { en: string; zh: string }; variant: string }> = {
    'best-overall': { label: { en: 'ğŸ† Best Overall', zh: 'ğŸ† ç»¼åˆæ¦œé¦–' }, variant: 'default' },
    'best-coding': { label: { en: 'ğŸ’» Best Coding', zh: 'ğŸ’» ç¼–ç¨‹ä¹‹ç‹' }, variant: 'default' },
    'best-math': { label: { en: 'ğŸ§® Best Math', zh: 'ğŸ§® æ•°å­¦å† å†›' }, variant: 'default' },
    'best-reasoning': { label: { en: 'ğŸ§  Best Reasoning', zh: 'ğŸ§  æ¨ç†å¤§å¸ˆ' }, variant: 'default' },
    'best-value': { label: { en: 'ğŸ’° Best Value', zh: 'ğŸ’° æ€§ä»·æ¯”ä¹‹ç‹' }, variant: 'secondary' },
    'open-source': { label: { en: 'ğŸ”“ Open Source', zh: 'ğŸ”“ å¼€æº' }, variant: 'outline' },
    'long-context': { label: { en: 'ğŸ“š Long Context', zh: 'ğŸ“š è¶…é•¿ä¸Šä¸‹æ–‡' }, variant: 'secondary' },
    'multilingual': { label: { en: 'ğŸŒ Multilingual', zh: 'ğŸŒ å¤šè¯­è¨€' }, variant: 'secondary' }
  }
  
  return badgeMap[badge]
}

